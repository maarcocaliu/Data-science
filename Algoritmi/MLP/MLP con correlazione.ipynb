{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importazione delle librerie necessarie\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================\n",
    "# 1. Caricamento dei dati\n",
    "# ============================\n",
    "# ============================\n",
    "# 1. Caricamento e Pulizia dei Dati\n",
    "# ============================\n",
    "# Parametri di connessione\n",
    "host = \"localhost\"\n",
    "port = \"5432\"\n",
    "dbname = \"DataScience\"\n",
    "user = \"postgres\"\n",
    "password = \"2430\"\n",
    "\n",
    "# Connessione a PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    host=host,\n",
    "    port=port,\n",
    "    dbname=dbname,\n",
    "    user=user,\n",
    "    password=password\n",
    ")\n",
    "\n",
    "# Query sulla vista\n",
    "query = \"SELECT * FROM public.mts_anagrafica\"\n",
    "# Caricare i dati in un DataFrame di Pandas\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Chiudere la connessione\n",
    "conn.close()\n",
    "\n",
    "# Visualizzare i dati\n",
    "print(\"Primi dati caricati:\")\n",
    "print(df.head())\n",
    "\n",
    "# Pulizia dei dati\n",
    "df = df.dropna()\n",
    "df.loc[:, \"giorno\"] = pd.to_datetime(df[\"giorno\"], format=\"%d/%m/%Y\").dt.date\n",
    "\n",
    "# Conversione della colonna \"giorno\" in formato datetime\n",
    "df[\"giorno\"] = pd.to_datetime(df[\"giorno\"], dayfirst=True)\n",
    "\n",
    "# Rimozione delle righe con valori NaN (se presenti)\n",
    "df = df.dropna()\n",
    "\n",
    "# Ordinamento del dataset per \"postazione\" e \"giorno\"\n",
    "df = df.sort_values(by=[\"postazione\", \"giorno\"]).reset_index(drop=True)\n",
    "\n",
    "# Calcolare la matrice di correlazione tra tutte le postazioni\n",
    "correlation_matrix = df.pivot_table(values=\"transiti\", index=\"giorno\", columns=\"postazione\").corr()\n",
    "\n",
    "# Visualizzare la matrice di correlazione\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(correlation_matrix, cmap='coolwarm', interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(correlation_matrix.columns)), correlation_matrix.columns, rotation=45)\n",
    "plt.yticks(range(len(correlation_matrix.columns)), correlation_matrix.columns)\n",
    "plt.title('Matrice di Correlazione tra le Postazioni')\n",
    "plt.show()\n",
    "\n",
    "# Funzione per creare sequenze temporali con feature aggiuntive\n",
    "def crea_sequenze_con_correlazione(dati_postazione, lookback, correlation_matrix, forecast_date):\n",
    "    \"\"\"\n",
    "    Crea sequenze temporali per il forecasting, includendo feature aggiuntive da postazioni correlate.\n",
    "    :param dati_postazione: DataFrame contenente i dati di una singola postazione.\n",
    "    :param lookback: Numero di giorni da usare come input per la previsione.\n",
    "    :param correlation_matrix: Matrice di correlazione tra le postazioni.\n",
    "    :param forecast_date: Data per cui fare il forecast (opzionale).\n",
    "    :return: Sequenze (X) e target (y).\n",
    "    \"\"\"\n",
    "    sequenze = []\n",
    "    target = []\n",
    "    \n",
    "    # Seleziona la postazione con la massima correlazione per la postazione corrente\n",
    "    strada_correlata = correlation_matrix[dati_postazione[\"postazione\"].iloc[0]].idxmax()\n",
    "    \n",
    "    if forecast_date is not None:\n",
    "        dati_postazione = dati_postazione[dati_postazione[\"giorno\"] < forecast_date]\n",
    "\n",
    "    for i in range(len(dati_postazione) - lookback):\n",
    "        # Estrai le feature per la sequenza corrente\n",
    "        X_seq_transiti = dati_postazione.iloc[i:i+lookback][\"transiti\"].values.flatten()\n",
    "        X_seq_leggeri = dati_postazione.iloc[i:i+lookback][\"trleggeri\"].values.flatten()\n",
    "        X_seq_pesanti = dati_postazione.iloc[i:i+lookback][\"trpesanti\"].values.flatten()\n",
    "        X_seq_feriali = dati_postazione.iloc[i:i+lookback][\"trferiali\"].values.flatten()\n",
    "        X_seq_festivi = dati_postazione.iloc[i:i+lookback][\"trfestivi\"].values.flatten()\n",
    "        X_seq_ngiornosettimana = dati_postazione.iloc[i:i+lookback][\"ngiornosettimana\"].values.flatten()\n",
    "\n",
    "        # Aggiungi anche i dati della postazione correlata\n",
    "        dati_correlata = df[df[\"postazione\"] == strada_correlata].iloc[i:i+lookback]\n",
    "        X_seq_correlata = dati_correlata[\"transiti\"].values.flatten()  \n",
    "\n",
    "        # Combina tutte le feature in un'unica sequenza\n",
    "        X_seq = np.concatenate((X_seq_transiti, X_seq_leggeri, X_seq_pesanti, X_seq_feriali, X_seq_festivi, \n",
    "            X_seq_ngiornosettimana, X_seq_correlata))\n",
    "\n",
    "        # Target (transiti totali del giorno successivo)\n",
    "        y_target = dati_postazione.iloc[i+lookback][\"transiti\"]\n",
    "\n",
    "        sequenze.append(X_seq)\n",
    "        target.append(y_target)\n",
    "\n",
    "    return np.array(sequenze), np.array(target)\n",
    "\n",
    "# Parametri\n",
    "lookback = 14  # Numero di giorni da usare per la previsione\n",
    "forecast_date = pd.to_datetime(\"2019-12-31\")  # Data per cui fare il forecast\n",
    "\n",
    "# Lista per memorizzare i risultati\n",
    "risultati = []\n",
    "\n",
    "# Iterazione su ogni postazione\n",
    "for postazione in df[\"postazione\"].unique():\n",
    "    # Filtra i dati per la postazione corrente\n",
    "    dati_postazione = df[df[\"postazione\"] == postazione].copy()\n",
    "\n",
    "    # Se non ci sono abbastanza dati, salta questa postazione\n",
    "    if len(dati_postazione) < lookback + 1:\n",
    "        continue\n",
    "\n",
    "    # Creazione delle sequenze per il training, includendo la correlazione\n",
    "    X, y = crea_sequenze_con_correlazione(dati_postazione, lookback, correlation_matrix, forecast_date)\n",
    "\n",
    "    # Normalizzazione dei dati\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "    X_scaled = scaler_X.fit_transform(X)\n",
    "    y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Divisione in training e test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Definizione del modello MLP\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=lookback * 7, activation=\"relu\"))  # Input dimension aggiornata (7 feature)\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compilazione del modello\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"mean_squared_error\")\n",
    "\n",
    "    # Aggiunta di Early Stopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"val_loss\",  # Monitora la perdita sul validation set\n",
    "        patience=10,         # Numero di epoche senza miglioramenti prima di fermare l'addestramento\n",
    "        restore_best_weights=True  # Ripristina i pesi migliori alla fine\n",
    "    )\n",
    "\n",
    "    # Addestramento del modello con Early Stopping\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,          # Numero massimo di epoche\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping],  # Aggiungi il callback EarlyStopping\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Valutazione del modello sul test set\n",
    "    test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Postazione: {postazione}, Test Loss: {test_loss}\")\n",
    "\n",
    "    # Previsioni sul test set\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    y_pred_rescaled = scaler_y.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "    y_test_rescaled = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Memorizzazione dei risultati\n",
    "    risultati.append({\n",
    "        \"Postazione\": postazione,\n",
    "        \"Test Loss\": test_loss,\n",
    "        \"True Values\": y_test_rescaled,\n",
    "        \"Predicted Values\": y_pred_rescaled\n",
    "    })\n",
    "\n",
    "    # Forecasting per il 31 dicembre\n",
    "    X_forecast, y_forecast = crea_sequenze_con_correlazione(dati_postazione, lookback, correlation_matrix, forecast_date)\n",
    "    X_forecast_scaled = scaler_X.transform(X_forecast)\n",
    "    y_pred_forecast = model.predict(X_forecast_scaled).flatten()\n",
    "    y_pred_forecast_rescaled = scaler_y.inverse_transform(y_pred_forecast.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Verifica se il 31 dicembre Ã¨ presente nei dati\n",
    "    if forecast_date in dati_postazione[\"giorno\"].values:\n",
    "        valore_reale_31_dicembre = dati_postazione[dati_postazione[\"giorno\"] == forecast_date][\"transiti\"].values[0]\n",
    "        print(f\"Postazione: {postazione}, Predizione 31/12: {y_pred_forecast_rescaled[0]:.2f}, Valore Reale: {valore_reale_31_dicembre}\")\n",
    "    else:\n",
    "        print(f\"Postazione: {postazione}, Predizione 31/12: {y_pred_forecast_rescaled[0]:.2f}, Valore Reale: Dato non disponibile\")\n",
    "\n",
    "# Plot dei risultati per ogni postazione\n",
    "for risultato in risultati:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(risultato[\"True Values\"], label=\"True Values\", marker='o')\n",
    "    plt.plot(risultato[\"Predicted Values\"], label=\"Predicted Values\", marker='x')\n",
    "    plt.title(f\"True vs Predicted Values - Postazione {risultato['Postazione']}\")\n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.ylabel(\"Traffic Volume\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
